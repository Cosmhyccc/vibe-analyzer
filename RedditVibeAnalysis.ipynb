{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4971240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "# Set up Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id='TqR3ABukMVMQ6VK8FkHOow',          # Replace with your actual Client ID\n",
    "    client_secret='s8zHB0IWkC2k7Oh1EPh5iDGi52VPGQ',         # Replace with your actual Secret\n",
    "    user_agent='SentimentAnalyzer/1.0 by KungFuSaifooo'  # Your custom User-Agent string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cb4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit bans subreddit group \"r/DonaldTrump\"\n",
      "\n",
      "Congress has set out a bill to stop the FCC taking away our internet. PLEASE SPREAD THIS AS MUCH AS YOU CAN.\n",
      "\n",
      "John Oliver Blackmails Congress With Their Own Digital Data - The ‘Last Week Tonight’ host paid shady brokers for lawmakers’ digital histories — promising not to release the info so long as Congress passes legislation protecting all consumers’ data\n",
      "\n",
      "California-based game company Blizzard bans pro esports player and confiscates his prize money after he voices support for Hong Kong protesters\n",
      "\n",
      "Joe Biden calls game developers \"little creeps\" who make titles that \"teach you how to kill\"\n",
      "\n",
      "Hacker collective Anonymous declares 'cyber war' against Russia, disables state news website\n",
      "\n",
      "President of USA wants to ban advertising targeted toward kids\n",
      "\n",
      "If Reddit was half as verbal about net neutrality as they are about Star Wars Battlefront II, then we could stop ISP's and the FCC\n",
      "All it takes is one call. It's our internet. \n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "**https://www.battleforthenet.com/**\n",
      "\n",
      "EDIT: thank you for my first gold(s) kind strangers. All I want is for people to be aware and take action, not spend money on me.\n",
      "Comcast is trying to censor our pro-net neutrality website that calls for an investigation into fake FCC comments potentially funded by the cable lobby\n",
      "Fight for the Future has received [a cease and desist order](http://imgur.com/a/BI7YZ) from Comcast’s lawyers, claiming that [Comcastroturf.com](http://comcastroturf.com) - a pro-net neutrality site encouraging Internet users to investigate an astroturfing campaign possibly funded by the cable lobby - violates Comcast’s \"valuable intellectual property.\" The letter threatens legal action if the domain is not transferred to Comcast’s control.\n",
      "\n",
      "The notice is ironic, in that it’s a perfect example of why we need Title II based net neutrality protections that ban ISPs from blocking or throttling content. \n",
      "\n",
      "**If the FCC’s current proposal is enacted, there would be nothing preventing Comcast from simply censoring this site -- or other sites critical of their corporate policies -- without even bothering with lawyers.**\n",
      "\n",
      "The legal notice can be viewed [here](http://imgur.com/a/BI7YZ). It claims that [Comcastroturf.com](http://comcastroturf.com) violates the Anticybersquatting Consumer Protection Act and infringes on Comcast’s trademarks. Of course, these claims are legally baseless, since the site is clearly a form of First Amendment protected political speech and makes no attempt to impersonate Comcast. (See the case \"[Bosley Medical Institute vs. Kremer](https://en.wikipedia.org/wiki/Bosley_Medical_Institute,_Inc._v._Kremer)\" which held that a site critical of a company’s practices could not be considered trademark infringement, or the case Taubman vs. Webfeats, which decided that *sucks.com domain names—in this case taubmansucks.com—were free speech)\n",
      "\n",
      "[Comcastroturf.com](http://comcastroturf.com) criticizes the cable lobby and encourages Internet users to search the Federal Communication Commission (FCC)’s docket to check if a fake comment was submitted using their name and address to attack Title II based net neutrality protections. It has been [widely reported](https://www.bna.com/fcc-set-move-n73014451155/) that more than 450,000 of these comments have been submitted to the FCC -- and as a result of the site at [Comcastroturf.com](http://comcastroturf.com), Fight for the Future [has heard](https://www.fightforthefuture.org/news/2017-05-18-fcc-ignores-growing-evidence-of-fraud-moves-ahead/) from dozens of people who say that anti-net neutrality comments were submitted using their personal information without their permission. We have connected individuals with Attorneys Generals and have called for the FCC act immediately to investigate this potential fraud.\n",
      "\n",
      "Companies like Comcast have a long history of funding shady astroturfing operations like the one we are trying to expose with [Comcastroturf.com](http://comcastroturf.com), and also a long history of engaging in censorship. This is exactly why we need net neutrality rules, and why we can’t trust companies like Comcast to just \"behave\" when they have abused their power time and time again.\n",
      "\n",
      "Fight for the Future has no intention of taking down [Comcastroturf.com](http://comcastroturf.com), and we would be happy to discuss the matter with Comcast in court.\n",
      "\n",
      "Bernie Sanders unveils plan to boost broadband access, break up internet and cable titans: “We are going to take on the greedy internet, telecom, and cable monopolies and put an end to their absurd price gouging”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('technology')\n",
    "top_posts = subreddit.top(limit=10)\n",
    "\n",
    "for post in top_posts:\n",
    "    print(post.title)\n",
    "    print(post.selftext)  # This is the body of the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be96215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Example text for sentiment analysis\n",
    "text = \"Here's what the tech industry is feeling\"\n",
    "\n",
    "# Create a TextBlob object\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment = blob.sentiment\n",
    "print(sentiment)  # Outputs polarity and subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de799ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.47651515151515156, subjectivity=0.7848484848484848)\n"
     ]
    }
   ],
   "source": [
    "text = \"I hate this new technology! It's absolutely stupid.\"\n",
    "blob = TextBlob(text)\n",
    "print(blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f621cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56b5288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the latest technology trends include artificial intelligence (AI) and machine learning, Internet of Things (IoT), 5G technology, virtual and augmented reality (VR/AR), blockchain technology, cybersecurity solutions, and quantum computing. These advancements are rapidly transforming various industries with improved automation, connectivity, data processing capabilities, and enhanced user experiences. Additionally, sustainability and green technologies are becoming increasingly important as organizations prioritize environmentally friendly solutions.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a brief summary of the latest technology trends.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b693535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of r/technology subreddit in the last 24 hours:\n",
      "\n",
      "The Trump campaign reports being hacked, resulting in the leak of 14 hours of secret training videos from Project 2025. Other headlines include a Tesla owner causing a fire by plugging into a power line, Google Chrome disabling extensions like uBlock Origin, Iran targeting the 2024 US election, issues with OnlyFans, a database of personal information being stolen, Wikipedia adapting to ChatGPT, a new electric plane design, and Microsoft retiring Paint 3D.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import praw\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Set up Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id='TqR3ABukMVMQ6VK8FkHOow',\n",
    "    client_secret='s8zHB0IWkC2k7Oh1EPh5iDGi52VPGQ',\n",
    "    user_agent='SentimentAnalyzer/1.0 by KungFuSaifooo'\n",
    ")\n",
    "\n",
    "# Fetch top posts from r/technology subreddit from the last 24 hours\n",
    "subreddit = reddit.subreddit('technology')\n",
    "top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "\n",
    "# Combine the titles and selftexts of the posts into a single document\n",
    "combined_content = \"\"\n",
    "for post in top_posts:\n",
    "    combined_content += post.title + \". \" + post.selftext + \"\\n\\n\"\n",
    "\n",
    "# Generate a summary using GPT-3.5-turbo\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following content:\\n\\n{combined_content}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the summary\n",
    "summary = response['choices'][0]['message']['content'].strip()\n",
    "print(\"Here's what the tech culture is feeling:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d13f9e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Trump campaign reports being hacked, resulting in the leak of 14 hours of secret training videos from Project 2025. Other headlines include a Tesla owner causing a fire by plugging into a power line, Google Chrome disabling extensions like uBlock Origin, Iran targeting the 2024 US election, issues with OnlyFans, a database of personal information being stolen, Wikipedia adapting to ChatGPT, a new electric plane design, and Microsoft retiring Paint 3D.\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('news')\n",
    "top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "summary2 = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "print(summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1840b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algerian boxer Imane Khelif, at centre of Olympics gender row, files legal complaint over online harassment\n",
      "Medical examiner determines dead woman found entangled in O'Hare baggage machinery died by suicide\n",
      "Uvalde shooter’s uncle begged police to let him talk to the gunman\n",
      "Steph Curry dazzles again as USA beat France for gold in men’s basketball final\n",
      "American gymnast Jordan Chiles must return bronze medal after court mandates score change, IOC says\n",
      "Judge in Maryland rules Baltimore ‘baby bonus’ proposal is unconstitutional\n",
      "UH researchers have developed two nasal sprays for respiratory viruses, COVID-19\n",
      "Reputed cartel boss Ismael ‘El Mayo’ Zambada reiterates claim he was ‘ambushed’ and ‘kidnapped’ by El Chapo’s son \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    subreddit = reddit.subreddit('news')\n",
    "    top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "    for post in top_posts:\n",
    "        print(post.title)\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching posts: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f892fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching top posts from r/technology\n",
      "Fetching top posts from r/machinelearning\n",
      "Combined Content from Subreddits:\n",
      " \n",
      "\n",
      "### Posts from r/technology:\n",
      "Trump campaign says it was hacked. \n",
      "\n",
      "14 hours of Project 2025's secret training videos leaked in Trump Campaign hack.. \n",
      "\n",
      "Tesla owner catches car and house on fire after plugging directly into power line. \n",
      "\n",
      "Google Chrome Will Soon Disable Extensions like uBlock Origin: Here's What You Can Do!. \n",
      "\n",
      "Iran Targeting 2024 US Election. \n",
      "\n",
      "OnlyFans’ porn juggernaut fueled by a deception. \n",
      "\n",
      "A database of almost 3 billion people's personal information stolen from National Public Data, a background checking company, was for sale on the dark web for $3.5 million.. \n",
      "\n",
      "How Wikipedia is surviving in the age of ChatGPT. \n",
      "\n",
      "Fully electric 90-passenger plane could fly 500 miles. \n",
      "\n",
      "Microsoft to retire Paint 3D, plans to remove the app from Store across Windows devices. \n",
      "\n",
      "\n",
      "\n",
      "### Posts from r/machinelearning:\n",
      "[D] How is your neurips discussion period going?. How is your neurips discussion period going? \n",
      "\n",
      "Any funny anecdotes? \n",
      "\n",
      "[R] Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters. A new research paper introduces Tree Attention algorithm for parallelizing attention computation across multiple GPUs, using associative properties of logsumexp and max operations to structure reduction as a tree.\n",
      "\n",
      "Tree attention algorithm, enables cross-device decoding to be performed asymptotically faster (up to 8x faster) than alternative approaches such as Ring Attention, while also requiring significantly less communication volume and incurring 2x less peak memory.\n",
      "\n",
      "[P] Looking for a gradient descent approach. I had an idea for an approach to gradient descent that tries to 'jump' directly to a (predicted) location of a nearby minimum. It works by approximating the 2nd-5th order Taylor polynomial around a point, then solving for the minimum (if possible) and setting that point as the new x. Then, the process can be repeated. If the Taylor polynomial at any point is concave, then we can use more standard gradient descent methods.  \n",
      "  \n",
      "This seems like a rather simple approach, so I doubt it is novel, but I haven't been able to find anything like it online. Does anyone know what this approach is called or if it has been studied?\n",
      "\n",
      "I was inspired by Newton's method for finding roots and a mild disdain for hyperparameter tuning.\n",
      "\n",
      "  \n",
      "Here are desmos demos for the quadratic and cubic Taylor approximations:\n",
      "\n",
      "Quadratic Descent: [https://www.desmos.com/calculator/i2nsjaxzhy](https://www.desmos.com/calculator/i2nsjaxzhy)\n",
      "\n",
      "Cubic Descent: [https://www.desmos.com/calculator/kgkbcfdn7t](https://www.desmos.com/calculator/kgkbcfdn7t)\n",
      "\n",
      "[R] Achieving Human Level Competitive Robot Table Tennis. \n",
      "\n",
      "[D] Modeling a dynamic system using LSTM. Dear all,\n",
      "\n",
      "after looking this very well made [video](https://youtu.be/av8csD_yrgw?si=tOZs1-x-CVO2IyJz) about the modeling of a dynamical system using RNN and LSTM I decided to model my real system using the same concept. Basically I want to model the dynamic of my real robot in order to create a \"digital twin\" of the same. In other words, I want to recreate the same robot in a simulator, with virtual physics properties and move it as it were real.\n",
      "\n",
      "My robot is driven using a joystick which output on every axes a float between -1.0 and 1.0. I collected the data (the real robot hat sensors already working and implemented). For simplification, let's say, that I want to drive the following joint coordinate by moving my joystick axis from left to right (Fig. 1).\n",
      "\n",
      "[Fig. 1](https://preview.redd.it/gbmji1gjkwhd1.jpg?width=997&format=pjpg&auto=webp&s=e2f388f0bd7ed8065e44da7413d6b5fe6e52c518)\n",
      "\n",
      "I collected one hour long the data, then I trained a LSTM with a hidden size of 32 using the following data:\n",
      "\n",
      "* The input is a concatenation of the joystick input and the joint coordinate (the state of the robot)\n",
      "* The target is representation by the state of the robot in the next step. I simply copied the columns of the state and shifted it one unit backward. Fig.2 shows probably better then 1000 words.\n",
      "\n",
      "[Fig. 2](https://preview.redd.it/382ceklkkwhd1.jpg?width=270&format=pjpg&auto=webp&s=328fb9617e32fe34d41d41cd122d34e498b03428)\n",
      "\n",
      "Then I created sequences of lenght 200 and trained my LSTM.  \n",
      "The training converged very quickly and I was quite happy with the results. But somehow the virtual robot reacts strangely in the virtual environment. It jumps from one position to another with incredible speed and then moves very slowly. So it is not reacting as the real robot would move (the real one is more smooth during the movement).\n",
      "\n",
      "Am I missing something important in this kind of problem?  \n",
      "What should I still consider, in order to create a good digital twin of the real robot?\n",
      "\n",
      "Note aside:\n",
      "\n",
      "* despite the example above, I normalized all the movements into the range \\[-1, 1\\] or \\[0, 1\\]\n",
      "* all the data has been collected using ethernet cable (so no delay due to wireless communication and so on)\n",
      "* I used the LSTM classes of PyTorch and not a custom realization\n",
      "* The data were collected by generating sinusoids inputs with different frequency and covering all the range of the joint.\n",
      "* For the training I shuffled the data: randomly  a start index was chosen and a sequence of 200 element was cut and used for training.\n",
      "\n",
      "[R] Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks. \n",
      "\n",
      "[P] Vison Language Models from Scratch. \n",
      "\n",
      "[D] How do you select epoch from pretraining?. I am pre-training a ViT on about a million images, and from the papers it seems like the longer you pre-train the better performance is expected. \n",
      "But, in my case the 400th epoch performed way better than a 800th epoch on downstream tasks. \n",
      "Is it the case that the more the data the more the epoch?\n",
      "Should we keep a validation set while pre-training too?\n",
      "\n",
      "[Discussion] Resources for onnx model conversion . I've been working on an audio-based project for the past six months, primarily using TensorFlow due to the requirement of deploying models with TensorFlow Lite (TFLite). However, I've encountered limitations with TensorFlow in terms of audio-based augmentations like pitch shifting, Room Impulse Response (RIR), and SpecAugment. In contrast, PyTorch offers a richer set of tools for these tasks, making it more suitable for my project needs. \n",
      "\n",
      "Given this, I'm considering switching to PyTorch. However, I still need to convert PyTorch models into TensorFlow models for deployment. During my research, I discovered that ONNX is a popular approach for this conversion. However, it seems that the PyTorch models need to be structured in a specific way to be compatible with TensorFlow after conversion.\n",
      "\n",
      "Does anyone have a guide on how to structure PyTorch models for ONNX conversion, or know of a more flexible conversion technique?\n",
      "\n",
      "TL;DR: I'm working on an audio project using TensorFlow for TFLite deployment but considering switching to PyTorch due to its superior audio augmentation tools. I need to convert PyTorch models to TensorFlow and am looking for guidance on using ONNX for this or any other flexible conversion method.\n",
      "\n",
      "[R] WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries. A new paper aims to create a realistic benchmark **WildHallucinations** for assessing LLM factuality.\n",
      "\n",
      "\n",
      "Summary of the latest discussions in r/technology, r/artificialintelligence, and r/machinelearning:\n",
      "\n",
      "- The Trump campaign reported being hacked, with leaked secret training videos and concerns about Iran targeting the 2024 US election.\n",
      "  \n",
      "- A Tesla owner caused a fire by plugging the car directly into a power line.\n",
      "  \n",
      "- Google Chrome plans to disable extensions like uBlock Origin, prompting users to find alternatives.\n",
      "  \n",
      "- OnlyFans faces controversy regarding the source of its rapid growth.\n",
      "  \n",
      "- Personal data of 3 billion individuals stolen from National Public Data was for sale on the dark web.\n",
      "  \n",
      "- Discussions in r/technology cover the survival of Wikipedia in the era of ChatGPT, a new 90-passenger electric plane, and the retirement of Microsoft's Paint 3D.\n",
      "\n",
      "- Reddit r/machinelearning featured discussions on neurips, a new algorithm called Tree Attention for parallelizing attention computation, a gradient descent approach inspired by Taylor polynomials, and challenges in using LSTM to model a real robot system effectively.\n",
      "\n",
      "- Other topics in r/machinelearning include discussions on numerical reasoning tasks and converting PyTorch models to TensorFlow using ONNX.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import praw\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Set up Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id='TqR3ABukMVMQ6VK8FkHOow',\n",
    "    client_secret='s8zHB0IWkC2k7Oh1EPh5iDGi52VPGQ',\n",
    "    user_agent='SentimentAnalyzer/1.0 by KungFuSaifooo'\n",
    ")\n",
    "\n",
    "# List of subreddits to analyze\n",
    "subreddits = ['technology', 'machinelearning']\n",
    "\n",
    "# Initialize an empty string to store all combined content\n",
    "combined_content = \"\"\n",
    "\n",
    "# Loop through each subreddit and fetch top posts\n",
    "for subreddit_name in subreddits:\n",
    "    print(f\"Fetching top posts from r/{subreddit_name}\")\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "    \n",
    "    combined_content += f\"\\n\\n### Posts from r/{subreddit_name}:\\n\"\n",
    "    for post in top_posts:\n",
    "        combined_content += post.title + \". \" + post.selftext + \"\\n\\n\"\n",
    "\n",
    "# Print combined content to verify\n",
    "print(\"Combined Content from Subreddits:\\n\", combined_content)\n",
    "\n",
    "# Generate a summary using GPT-3.5-turbo with a unique prompt\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following content from multiple subreddits. Include recent discussions and avoid repetition. Here is the content:\\n\\n{combined_content}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the summary\n",
    "summary = response['choices'][0]['message']['content'].strip()\n",
    "print(\"Summary of the latest discussions in r/technology, r/artificialintelligence, and r/machinelearning:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fec2c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching top posts from r/technology\n",
      "Fetching top posts from r/machinelearning\n",
      "Summary of the latest discussions in r/technology and r/machinelearning:\n",
      "\n",
      "The key points from the content in r/technology include a Trump campaign hack, leaked training videos, a Tesla owner causing a fire, Google Chrome disabling extensions, Iran targeting the US election, a large data breach, advancements in electric planes, and Microsoft's decision to retire Paint 3D. The sentiment in this subreddit seems to be a mix of concerning news and technological advancements.\n",
      "\n",
      "Meanwhile, the discussions in r/machinelearning cover topics such as NeurIPS, a new Tree Attention algorithm for GPU clusters, a unique gradient descent approach, LSTM modeling for robotics, and converting PyTorch models to TensorFlow using ONNX. The sentiment in this subreddit appears to be more technical, focusing on research, algorithm development, and practical applications in machine learning.\n",
      "\n",
      "Overall, both subreddits are engaging with informative and technical topics, reflecting a positive sentiment characterized by curiosity, innovation, and problem-solving.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import praw\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Set up Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id='TqR3ABukMVMQ6VK8FkHOow',\n",
    "    client_secret='s8zHB0IWkC2k7Oh1EPh5iDGi52VPGQ',\n",
    "    user_agent='VibeAnalyzer'\n",
    ")\n",
    "\n",
    "# List of subreddits to analyze\n",
    "subreddits = ['technology', 'machinelearning']\n",
    "\n",
    "# Initialize an empty string to store all combined content\n",
    "combined_content = \"\"\n",
    "\n",
    "# Loop through each subreddit and fetch top posts\n",
    "for subreddit_name in subreddits:\n",
    "    try:\n",
    "        print(f\"Fetching top posts from r/{subreddit_name}\")\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "        \n",
    "        combined_content += f\"\\n\\n### Posts from r/{subreddit_name}:\\n\"\n",
    "        for post in top_posts:\n",
    "            combined_content += post.title + \". \" + post.selftext + \"\\n\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching posts from r/{subreddit_name}: {e}\")\n",
    "\n",
    "# Analyze the sentiment of the combined content using TextBlob\n",
    "blob = TextBlob(combined_content)\n",
    "polarity = blob.sentiment.polarity\n",
    "subjectivity = blob.sentiment.subjectivity\n",
    "\n",
    "# Use the sentiment to influence the summary\n",
    "sentiment_summary = f\"The overall sentiment in the r/technology and r/machinelearning subreddits in the last 24 hours appears to be {'positive' if polarity > 0 else 'negative' if polarity < 0 else 'neutral'}. The discussions have been {'largely subjective, reflecting personal opinions and speculations' if subjectivity > 0.5 else 'more objective, focusing on factual information and analysis'}.\"\n",
    "\n",
    "# Combine sentiment analysis with the OpenAI summary\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Based on the following content, provide a summary of the key points and overall sentiment:\\n\\n{combined_content}\\n\\n{sentiment_summary}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "summary = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary of the latest discussions in r/technology and r/machinelearning:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2f873b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing vibe levels... Scanning the vibe-o-meter... One moment king\n",
      "Analyzing vibe levels... Scanning the vibe-o-meter... One moment king\n",
      "Analyzing vibe levels... Scanning the vibe-o-meter... One moment king\n",
      "Here's what the tech culture is feeling!\n",
      "\n",
      "The tech culture is buzzing with riveting developments and controversies. From the drama-laden leak of Project 2025's secret training videos linked to the Trump campaign hack, to Google's controversial move to disable popular extensions like uBlock Origin in Chrome, discussions are intense. In a surprising breach, thousands of corporate secrets were exposed, while on the aviation front, a fully electric 90-passenger plane could redefine regional travel with a 500-mile range. Educational reforms in the UK aim to arm children against extremist content and fake news, reflecting a growing awareness of digital threats. The nostalgia of Redbox DVD kiosks edges closer to an end as its parent company faces liquidation, signifying a broader shift towards digital media. Meanwhile, Microsoft is set to retire Paint 3D, adding to the bittersweet narrative of evolving tech.\n",
      "\n",
      "In machine learning, the scene is equally dynamic. A breakthrough Tree Attention algorithm promises faster and more efficient GPU cluster operations, eclipsing the established Ring Attention method. Users engage in practical problem-solving, from modeling robotic systems with LSTMs to refining gradient descent techniques. A hot topic is the development of \"Beatlander,\" an AI turning hums into professional music tracks, showcasing the blend of creativity and tech. The concerns around AI’s rapid progression are palpable with initiatives to curb potential threats like AI-induced unemployment or even existential risks. Meanwhile, innovative minds are exploring seamless AI integrations like JENOVA, which optimally utilizes multiple models to enhance user experience. The discourse is a mix of excitement, innovation, and cautious introspection about the future AI landscape.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import praw\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Set up Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id='TqR3ABukMVMQ6VK8FkHOow',\n",
    "    client_secret='s8zHB0IWkC2k7Oh1EPh5iDGi52VPGQ',\n",
    "    user_agent='Vibe_analyzer/V1.0'\n",
    ")\n",
    "\n",
    "# List of subreddits to analyze\n",
    "subreddits = ['technology', 'machinelearning', 'artificialinteligence']\n",
    "\n",
    "# Initialize an empty string to store all combined content\n",
    "combined_content = \"\"\n",
    "\n",
    "# Loop through each subreddit and fetch top posts\n",
    "for subreddit_name in subreddits:\n",
    "    try:\n",
    "        print(f\"Analyzing vibe levels... Scanning the vibe-o-meter... One moment king\")\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "        \n",
    "        combined_content += f\"\\n\\n### Posts from r/{subreddit_name}:\\n\"\n",
    "        for post in top_posts:\n",
    "            combined_content += post.title + \". \" + post.selftext + \"\\n\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching posts from r/{subreddit_name}: {e}\")\n",
    "\n",
    "# Use OpenAI's GPT-4o to generate a focused summary\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Based on the following content provide a concise 2-paragraph summary that captures the key discussions and overall sentiment. The summary should tell the user some detail as to what the discussions were about. make it sound cool and interesting to read, not boring. Do not name the subreddits anywhere in the output, keep it natural. The summary should give a clear sense of what's happening in the tech culture:\\n\\n{combined_content}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "summary = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Print the improved summary\n",
    "print(\"Here's what the tech culture is feeling!\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b1eded",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask\n\u001b[1;32m      3\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mroute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhome\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Hello, Flask!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a47168f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask\n\u001b[1;32m      3\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mroute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhome\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Hello, Flask!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
